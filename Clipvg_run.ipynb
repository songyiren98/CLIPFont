{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7DCzf-EHzL_"
      },
      "source": [
        "## Directions\n",
        "\n",
        "\n",
        "1. Click \"Connect\" in the top right corner\n",
        "2. Runtime -> Change runtime type -> Hardware accelerator -> GPU\n",
        "3. Click the run button on \"Pre Installation\". This will install dependencies, it may take a while.\n",
        "4. **Important:** Runtime -> Restart Runtime\n",
        "5. Run the imports and function definition sections.\n",
        "  - **Important:** The \"Imports and Notebook Utilities\" cell will print which GPU you have been assigned.  This notebook needs to be run with a T4, P4, P100, or V100 GPU (**K80 will not work**, unfortunately). You may have to restart the machine a few times until you get assigned a valid GPU (Runtime -> manage sessions -> terminate the session -> re-connect to new session).\n",
        "6. Run the `style_clip_draw()` function with your own parameters. See the last few cells for examples\n",
        "\n",
        "## StyleCLIPDraw Parameters\n",
        "\n",
        "The style_clip_draw() function has many parameters to play with.  In the last few cells, you can see a few examples of the function in action.\n",
        "\n",
        "```\n",
        "def style_clip_draw(...):\n",
        "    Perform StyleCLIPDraw using a given text prompt and style image\n",
        "    args:\n",
        "        prompt (str) : Text prompt to draw\n",
        "        style_path(str) : Style image path or url\n",
        "    kwargs:\n",
        "        num_paths (int) : Number of brush strokes\n",
        "        num_iter(int) : Number of optimization iterations\n",
        "        max_width(float) : Maximum width of a brush stroke in pixels\n",
        "        num_augs(int) : Number of image augmentations\n",
        "        style_opt_freq(int) : How often to do style optimization. Low value is high frequency\n",
        "        style_opt_iter(int) : How many iterations to do in the style optimization loop\n",
        "        debug(bool) : Print intermediate canvases and losses for debugging\n",
        "```\n",
        "\n",
        "### Acknowledgement \n",
        "StyleCLIPDraw is built off of [CLIPDraw (Frans et al. 2021)](https://arxiv.org/pdf/2106.14843.pdf) [(Their code)](https://github.com/kvfrans/clipdraw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9s1XGprUNOb",
        "outputId": "a39b4337-ea46-42f2-b31d-3ea5f3f33750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MUIEYjtVN8A",
        "outputId": "2906b304-3a24-4594-d451-1e9e4eb3e85a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['shared_edge_compare.py',\n",
              " 'quadratic_distance_approx.py',\n",
              " '.gitignore',\n",
              " 'simple_transform_svg.py',\n",
              " 'utils.py',\n",
              " 'image_compare.py',\n",
              " 'Makefile',\n",
              " 'refine_svg.py',\n",
              " 'render_svg.py',\n",
              " 'seam_carving.py',\n",
              " 'template.py',\n",
              " 'gaussian_blur.py',\n",
              " 'geometry.py',\n",
              " 'finite_difference_comp.py',\n",
              " 'curve_subdivision.py',\n",
              " 'test_eval_positions.py',\n",
              " 'optimize_pixel_filter.py',\n",
              " 'single_circle_outline.py',\n",
              " 'painterly_rendering.py',\n",
              " 'clipvg_font.py',\n",
              " '.DS_Store',\n",
              " '.ipynb_checkpoints',\n",
              " 'results',\n",
              " 'imgs',\n",
              " '__pycache__',\n",
              " 'clipvg',\n",
              " 'generative_models']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "path=\"/content/drive/My Drive/clipvg1/apps\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dyyH781qzIC",
        "outputId": "39b2478f-01ac-4185-d2b6-f82464d82335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Tensorflow 1 is deprecated, and support will be removed on August 1, 2022.\n",
            "After that, `%tensorflow_version 1.x` will throw an error.\n",
            "\n",
            "Your notebook should be updated to use Tensorflow 2.\n",
            "See the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "CUDA version: 11.1\n",
            "/content\n",
            "Cloning into 'diffvg'...\n",
            "remote: Enumerating objects: 279, done.\u001b[K\n",
            "remote: Total 279 (delta 0), reused 0 (delta 0), pack-reused 279\u001b[K\n",
            "Receiving objects: 100% (279/279), 10.27 MiB | 18.25 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n",
            "/content/diffvg\n",
            "Submodule 'pybind11' (https://github.com/pybind/pybind11.git) registered for path 'pybind11'\n",
            "Submodule 'thrust' (https://github.com/thrust/thrust.git) registered for path 'thrust'\n",
            "Cloning into '/content/diffvg/pybind11'...\n",
            "Cloning into '/content/diffvg/thrust'...\n",
            "Submodule path 'pybind11': checked out '72b06b86b3824781f31c790dfce67e26e6307816'\n",
            "Submodule 'tools/clang' (https://github.com/wjakob/clang-cindex-python3.git) registered for path 'pybind11/tools/clang'\n",
            "Cloning into '/content/diffvg/pybind11/tools/clang'...\n",
            "Submodule path 'pybind11/tools/clang': checked out '6a00cbc4a9b8e68b71caf7f774b3f9c753ae84d5'\n",
            "Submodule path 'thrust': checked out 'ff00c813aa3a6bbfd1d8c338313f382b6b340005'\n",
            "Submodule 'cub' (https://github.com/thrust/cub.git) registered for path 'thrust/dependencies/cub'\n",
            "Cloning into '/content/diffvg/thrust/dependencies/cub'...\n",
            "Submodule path 'thrust/dependencies/cub': checked out '2442f44532ffcc53298c7e3a298feb5134563860'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-ngnqyul7\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-ngnqyul7\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369409 sha256=ceee807c8afe4fd37d155b3018b548bf703064be6c63971a0d3fc60b2c9d9f08\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vwfs_68q/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ]
        }
      ],
      "source": [
        "#@title Pre Installation {vertical-output: true}\n",
        "%tensorflow_version 1.x\n",
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "# if CUDA_version == \"10.0\":\n",
        "#     torch_version_suffix = \"+cu100\"\n",
        "# elif CUDA_version == \"10.1\":\n",
        "#     torch_version_suffix = \"+cu101\"\n",
        "# elif CUDA_version == \"10.2\":\n",
        "#     torch_version_suffix = \"+cu102\"\n",
        "# elif CUDA_version == \"11.0\":\n",
        "#     torch_version_suffix = \"+cu110\"\n",
        "# elif CUDA_version == \"11.1\":\n",
        "#     torch_version_suffix = \"+cu111\"\n",
        "# elif CUDA_version == \"11.2\":\n",
        "#     torch_version_suffix = \"+cu112\"\n",
        "# else:\n",
        "#     torch_version_suffix = \"+cu110\"\n",
        "# # !pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html &> /dev/null\n",
        "# !pip install --upgrade torch\n",
        "\n",
        "%cd /content/\n",
        "!pip install svgwrite           &> /dev/null\n",
        "!pip install svgpathtools       &> /dev/null\n",
        "!pip install cssutils           &> /dev/null\n",
        "!pip install numba              &> /dev/null\n",
        "!pip install torch-tools        &> /dev/null\n",
        "!pip install visdom             &> /dev/null\n",
        "\n",
        "!git clone https://github.com/BachiLi/diffvg\n",
        "%cd diffvg\n",
        "# !ls\n",
        "!git submodule update --init --recursive\n",
        "!python setup.py install           &> /dev/null\n",
        "\n",
        "!pip install ftfy regex tqdm       &> /dev/null\n",
        "!pip install git+https://github.com/openai/CLIP.git --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIq-54jQOeuL",
        "outputId": "d7ad7fe4-8a3f-4a6d-f0cd-15de9cd91e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting template\n",
            "  Downloading template-0.7.6-py2.py3-none-any.whl (19 kB)\n",
            "Collecting jmespath\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from template) (2.11.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from template) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->template) (2.0.1)\n",
            "Installing collected packages: toml, jmespath, template\n",
            "Successfully installed jmespath-1.0.1 template-0.7.6 toml-0.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XziMA2JeVr2v",
        "outputId": "878d8634-afb9-4de2-be56-e76f21eb7cc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['shared_edge_compare.py',\n",
              " 'quadratic_distance_approx.py',\n",
              " '.gitignore',\n",
              " 'simple_transform_svg.py',\n",
              " 'utils.py',\n",
              " 'image_compare.py',\n",
              " 'Makefile',\n",
              " 'refine_svg.py',\n",
              " 'render_svg.py',\n",
              " 'seam_carving.py',\n",
              " 'template.py',\n",
              " 'gaussian_blur.py',\n",
              " 'geometry.py',\n",
              " 'finite_difference_comp.py',\n",
              " 'curve_subdivision.py',\n",
              " 'test_eval_positions.py',\n",
              " 'optimize_pixel_filter.py',\n",
              " 'single_circle_outline.py',\n",
              " 'painterly_rendering.py',\n",
              " 'clipvg_font.py',\n",
              " '.DS_Store',\n",
              " '.ipynb_checkpoints',\n",
              " 'results',\n",
              " 'imgs',\n",
              " '__pycache__',\n",
              " 'clipvg',\n",
              " 'generative_models']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import os\n",
        "path=\"/content/drive/My Drive/clipvg1/apps\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZffD5DzWMqL",
        "outputId": "4e3c36e7-ee64-4914-a7e5-90bdcb01a38a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: path: No such file or directory\n",
            "tensor([[ 3.7479e-03,  1.2207e-02, -4.3831e-03, -2.6367e-02,  3.1952e-02,\n",
            "         -5.0232e-02,  9.5749e-03, -4.6936e-02,  4.1779e-02, -2.0142e-03,\n",
            "         -8.8348e-03, -4.4464e-02,  5.3902e-03, -3.5126e-02,  2.9816e-02,\n",
            "         -2.0676e-03,  2.6962e-02, -6.7329e-03, -5.8365e-03,  1.8661e-02,\n",
            "          3.9642e-02,  1.7670e-02,  1.8280e-02, -1.2680e-02,  6.3562e-04,\n",
            "          1.9653e-02,  4.3182e-02,  1.4900e-02,  3.0975e-03,  1.9426e-03,\n",
            "          5.3787e-03, -3.6469e-02,  3.7422e-03,  5.9414e-04,  1.4315e-03,\n",
            "         -1.5078e-03,  1.9646e-03, -2.1561e-02, -6.4163e-03, -9.8648e-03,\n",
            "         -1.1044e-03,  8.7585e-03,  3.3112e-02, -1.6296e-02, -1.7822e-04,\n",
            "          2.1240e-02,  5.9586e-03, -1.1474e-04,  8.4076e-03,  3.1891e-03,\n",
            "          3.3722e-02, -6.4659e-03, -2.5085e-02, -6.4011e-03,  3.6224e-02,\n",
            "         -2.7298e-02,  1.7899e-02,  3.8719e-03,  1.8417e-02, -1.3763e-02,\n",
            "          2.5986e-02,  4.8027e-03, -2.7409e-03,  1.0544e-02,  4.0344e-02,\n",
            "         -2.1877e-03,  5.6763e-03, -3.5954e-03,  1.1276e-02,  5.1689e-03,\n",
            "          3.1090e-03, -2.2163e-03,  1.3153e-02, -1.4618e-02, -1.8814e-02,\n",
            "          1.9426e-03,  1.3397e-02, -1.7807e-02,  1.6541e-02, -1.0147e-02,\n",
            "         -2.2385e-02, -2.3407e-02, -9.2087e-03,  1.0170e-02,  4.9362e-03,\n",
            "         -4.4189e-02,  8.4152e-03,  1.7328e-03,  2.7969e-02, -6.6910e-03,\n",
            "         -8.6288e-03, -9.1476e-03, -1.2457e-01, -1.7899e-02, -2.1271e-02,\n",
            "          5.2214e-04,  2.1500e-02,  3.0014e-02,  2.0523e-02,  2.6505e-02,\n",
            "          1.1513e-02,  2.9236e-02, -6.0944e-02,  1.8339e-03,  3.3447e-02,\n",
            "         -2.2003e-02, -3.9062e-02, -7.5684e-03,  6.7177e-03, -4.4647e-02,\n",
            "          1.7380e-02, -7.2021e-02,  1.6479e-02,  1.0094e-02, -1.0071e-02,\n",
            "          3.9490e-02, -1.7975e-02, -1.4839e-02,  1.2314e-02,  9.8343e-03,\n",
            "          2.9739e-02, -9.7351e-02,  4.0192e-02, -2.4277e-02, -1.1730e-03,\n",
            "         -3.2867e-02, -5.1832e-04,  9.8801e-03, -3.0380e-02,  5.2704e-02,\n",
            "          1.4420e-02, -4.5891e-03, -5.6496e-03,  5.8984e-01, -2.2614e-02,\n",
            "         -3.7964e-02,  2.7130e-02, -1.0544e-02, -2.1877e-03, -1.6342e-02,\n",
            "         -3.3051e-02,  3.3325e-02,  9.7656e-03,  1.2428e-02,  2.3514e-02,\n",
            "          1.5175e-02, -7.7477e-03, -4.3640e-02, -1.4984e-02, -2.2430e-02,\n",
            "         -1.3451e-02,  7.1831e-03, -9.2087e-03,  7.4463e-02,  1.1101e-02,\n",
            "          2.2217e-02,  1.6508e-03, -3.5522e-02, -4.2610e-03,  1.0361e-02,\n",
            "          2.2736e-02,  3.3588e-03, -1.4677e-03, -3.5522e-02,  3.5126e-02,\n",
            "         -4.0497e-02,  6.1264e-03, -3.2745e-02,  1.2680e-02,  1.2169e-03,\n",
            "         -1.6541e-02, -1.6891e-02,  2.8076e-02, -4.0283e-02,  3.1525e-02,\n",
            "          3.7628e-02, -4.7607e-02,  1.0857e-02, -2.5436e-02, -3.0945e-02,\n",
            "          4.5357e-03,  1.2703e-02, -8.7509e-03, -3.7323e-02, -1.6144e-02,\n",
            "         -2.0981e-05, -2.1255e-02, -2.7100e-02,  9.6130e-03,  4.2152e-03,\n",
            "          7.3433e-03, -1.6281e-02, -2.8214e-02,  2.3663e-05,  3.1403e-02,\n",
            "         -1.4519e-02, -2.2430e-02, -6.7863e-03,  1.8188e-02, -6.2599e-03,\n",
            "          2.9434e-02,  9.2010e-03, -3.0212e-03,  2.6306e-02,  1.3298e-02,\n",
            "          1.5121e-02,  2.1133e-02, -1.0208e-02, -1.4854e-02, -3.4199e-03,\n",
            "          4.9377e-02, -1.0574e-02, -4.6372e-04,  2.6962e-02, -1.4435e-02,\n",
            "          2.2125e-02, -9.7885e-03,  2.1515e-02, -3.6407e-02, -1.8738e-02,\n",
            "         -2.8198e-02, -2.7069e-02, -4.2391e-04, -2.2476e-02, -1.2474e-02,\n",
            "          2.9480e-02,  1.1467e-02, -3.7476e-02,  2.9205e-02,  1.7059e-02,\n",
            "         -4.5586e-03, -9.7046e-03,  1.0620e-02, -3.7384e-02,  2.2781e-02,\n",
            "          2.9572e-02, -2.1774e-02,  1.6769e-02, -2.0126e-02,  1.7517e-02,\n",
            "         -6.1073e-03,  1.4038e-02, -4.6570e-02, -3.4332e-02, -2.3560e-02,\n",
            "          2.5711e-02, -8.5297e-03,  1.3725e-02, -1.1864e-02, -2.5558e-02,\n",
            "         -2.0676e-02, -5.0690e-02, -2.0035e-02,  1.2497e-02,  1.3268e-02,\n",
            "          2.3537e-03, -2.7328e-02,  4.1542e-03, -2.1851e-02,  5.2223e-03,\n",
            "          3.1223e-03,  1.2344e-02, -4.0436e-02, -2.1851e-02, -1.9501e-02,\n",
            "         -1.4351e-02,  3.3600e-02, -3.0975e-02, -1.7624e-02, -9.4299e-03,\n",
            "          1.6937e-02,  1.5007e-02,  1.9608e-02,  1.4000e-02, -3.2104e-02,\n",
            "          5.9937e-02,  1.5411e-02, -1.9073e-02, -1.6222e-03,  2.3346e-02,\n",
            "         -1.0849e-02,  1.7181e-02, -4.8485e-03, -7.8812e-03, -3.1830e-02,\n",
            "          8.9493e-03, -1.8433e-02,  7.8964e-03,  2.0905e-02, -1.4824e-02,\n",
            "          6.6895e-02, -6.9466e-03,  1.8188e-02,  4.8256e-03, -2.9144e-02,\n",
            "          1.3237e-02, -8.8072e-04,  2.1347e-02,  1.4671e-02, -4.4983e-02,\n",
            "         -1.2985e-02,  3.0991e-02,  2.1744e-02, -3.6931e-04, -2.9541e-02,\n",
            "         -7.6965e-02, -1.0811e-02,  5.2032e-02,  1.9836e-02,  1.8997e-02,\n",
            "         -1.9012e-02,  1.2016e-02,  5.8984e-01,  1.2474e-02,  3.7415e-02,\n",
            "          2.7466e-02, -7.1144e-03, -3.2654e-02, -3.3875e-02, -9.0332e-03,\n",
            "         -3.0945e-02,  2.9541e-02,  2.2476e-02,  7.1602e-03,  4.0344e-02,\n",
            "         -4.9019e-03,  8.7433e-03,  5.7182e-03, -1.9974e-02, -8.7524e-02,\n",
            "          2.2232e-02,  7.0686e-03,  1.2634e-02,  9.4757e-03,  1.6647e-02,\n",
            "          3.3627e-03,  4.1931e-02,  1.2894e-03, -1.0582e-02, -5.5962e-03,\n",
            "         -1.6251e-02, -1.6693e-02, -2.9144e-02,  3.5583e-02,  1.1921e-03,\n",
            "         -2.3880e-02, -1.9226e-02,  2.4891e-03, -1.3590e-05,  3.6678e-03,\n",
            "         -4.6051e-02, -1.6983e-02,  2.3975e-03, -6.3553e-03, -7.2002e-04,\n",
            "         -7.9956e-03,  8.3084e-03,  9.0271e-02, -8.8835e-04,  3.8853e-03,\n",
            "          1.3023e-02, -3.9551e-02, -1.0399e-02, -5.9624e-03,  7.3425e-02,\n",
            "         -1.1383e-02,  1.2947e-02, -6.2065e-03,  1.0399e-02, -3.8696e-02,\n",
            "          1.7960e-02,  1.7700e-02,  1.3351e-02,  4.5276e-04,  2.4277e-02,\n",
            "         -3.3600e-02, -1.8677e-02,  3.3417e-02, -2.3708e-03, -2.1896e-02,\n",
            "          3.5034e-02, -3.7872e-02, -1.9012e-02,  1.5182e-03,  3.0212e-03,\n",
            "         -1.1253e-03, -3.1342e-02,  3.1662e-03, -3.8147e-02, -3.0684e-04,\n",
            "         -4.2480e-02,  5.9937e-02, -2.9488e-03, -3.8544e-02, -1.3954e-02,\n",
            "         -1.8950e-03, -6.3629e-03, -1.4900e-02,  2.4750e-02,  2.4529e-03,\n",
            "          1.2550e-02,  3.7750e-02, -1.0536e-02,  2.8458e-03,  4.0771e-02,\n",
            "          6.4182e-04,  4.0833e-02, -2.8519e-02, -3.8643e-03, -2.4567e-02,\n",
            "         -2.0447e-02,  1.2436e-02,  5.1697e-02,  5.2309e-04, -1.6647e-02,\n",
            "          8.9951e-03, -2.6283e-03, -3.2501e-02,  3.3234e-02, -4.7379e-03,\n",
            "         -9.1553e-04,  8.2855e-03, -5.7182e-03,  1.2001e-02,  6.2943e-04,\n",
            "         -1.3771e-02, -3.7518e-03,  2.5116e-02,  2.5162e-02,  2.5964e-04,\n",
            "          9.3918e-03, -5.3368e-03, -6.1218e-02, -1.9501e-02,  4.8218e-03,\n",
            "         -1.9867e-02,  1.6815e-02, -6.1111e-03, -3.6125e-03, -1.1780e-02,\n",
            "          7.4005e-03, -9.0332e-03, -4.6272e-03, -9.5139e-03,  4.1533e-04,\n",
            "         -2.0355e-02, -4.0970e-03, -9.3842e-03,  2.4376e-03, -4.8615e-02,\n",
            "          8.8882e-03,  4.0741e-03,  5.6458e-03,  3.4607e-02,  7.0419e-03,\n",
            "         -1.4160e-02,  1.7960e-02, -3.6335e-03, -4.8409e-03, -6.1393e-05,\n",
            "         -5.7907e-03,  2.1057e-03, -1.6846e-02,  1.6144e-02, -4.8332e-03,\n",
            "         -4.1046e-02,  1.4923e-02,  5.9853e-03, -1.3588e-02, -6.4545e-03,\n",
            "          3.4580e-03, -3.9154e-02,  9.5987e-04,  1.4656e-02, -3.9291e-03,\n",
            "         -1.7334e-02, -1.5190e-02,  2.5574e-02, -7.7286e-03,  1.1017e-02,\n",
            "         -1.3840e-02, -5.2216e-02,  2.0466e-03, -6.9923e-03,  1.7487e-02,\n",
            "          8.8348e-03, -1.6495e-02, -1.3992e-02,  1.0651e-02, -1.0811e-02,\n",
            "         -7.7782e-03,  6.5536e-03, -2.8961e-02,  1.6052e-02,  5.5199e-03,\n",
            "          7.6637e-03,  1.8112e-02, -2.7817e-02, -2.1744e-02,  7.7553e-03,\n",
            "          5.6114e-03, -1.4587e-02, -2.6321e-02, -2.4307e-02,  8.1116e-02,\n",
            "          1.4282e-02, -6.1302e-03, -4.2000e-03, -2.3605e-02, -2.8381e-03,\n",
            "          7.7343e-04,  3.0914e-02]], device='cuda:0', dtype=torch.float16)\n",
            "iteration: 0\n",
            "clip loss: 173.0\n",
            "total loss: 173.0\n",
            "iteration: 1\n",
            "clip loss: 172.5\n",
            "total loss: 172.5\n",
            "iteration: 2\n",
            "clip loss: 172.25\n",
            "total loss: 172.25\n",
            "iteration: 3\n",
            "clip loss: 172.25\n",
            "total loss: 172.25\n",
            "iteration: 4\n",
            "clip loss: 172.0\n",
            "total loss: 172.0\n",
            "iteration: 5\n",
            "clip loss: 171.5\n",
            "total loss: 171.5\n",
            "iteration: 6\n",
            "clip loss: 171.375\n",
            "total loss: 171.375\n",
            "iteration: 7\n",
            "clip loss: 171.375\n",
            "total loss: 171.375\n",
            "iteration: 8\n",
            "clip loss: 170.875\n",
            "total loss: 170.875\n",
            "iteration: 9\n",
            "clip loss: 171.0\n",
            "total loss: 171.0\n",
            "iteration: 10\n",
            "clip loss: 170.5\n",
            "total loss: 170.5\n",
            "iteration: 11\n",
            "clip loss: 170.5\n",
            "total loss: 170.5\n",
            "iteration: 12\n",
            "clip loss: 170.5\n",
            "total loss: 170.5\n",
            "iteration: 13\n",
            "clip loss: 169.75\n",
            "total loss: 169.75\n",
            "iteration: 14\n",
            "clip loss: 169.5\n",
            "total loss: 169.5\n",
            "iteration: 15\n",
            "clip loss: 169.75\n",
            "total loss: 169.75\n",
            "iteration: 16\n",
            "clip loss: 169.5\n",
            "total loss: 169.5\n",
            "iteration: 17\n",
            "clip loss: 169.5\n",
            "total loss: 169.5\n",
            "iteration: 18\n",
            "clip loss: 169.5\n",
            "total loss: 169.5\n",
            "iteration: 19\n",
            "clip loss: 168.75\n",
            "total loss: 168.75\n",
            "iteration: 20\n",
            "clip loss: 168.75\n",
            "total loss: 168.75\n",
            "iteration: 21\n",
            "clip loss: 168.625\n",
            "total loss: 168.625\n",
            "iteration: 22\n",
            "clip loss: 168.25\n",
            "total loss: 168.25\n",
            "iteration: 23\n",
            "clip loss: 168.375\n",
            "total loss: 168.375\n",
            "iteration: 24\n",
            "clip loss: 168.0\n",
            "total loss: 168.0\n",
            "iteration: 25\n",
            "clip loss: 167.875\n",
            "total loss: 167.875\n",
            "iteration: 26\n",
            "clip loss: 167.75\n",
            "total loss: 167.75\n",
            "iteration: 27\n",
            "clip loss: 167.5\n",
            "total loss: 167.5\n",
            "iteration: 28\n",
            "clip loss: 167.625\n",
            "total loss: 167.625\n",
            "iteration: 29\n",
            "clip loss: 167.5\n",
            "total loss: 167.5\n",
            "iteration: 30\n",
            "clip loss: 167.25\n",
            "total loss: 167.25\n",
            "iteration: 31\n",
            "clip loss: 166.75\n",
            "total loss: 166.75\n",
            "iteration: 32\n",
            "clip loss: 167.125\n",
            "total loss: 167.125\n",
            "iteration: 33\n",
            "clip loss: 166.75\n",
            "total loss: 166.75\n",
            "iteration: 34\n",
            "clip loss: 167.125\n",
            "total loss: 167.125\n",
            "iteration: 35\n",
            "clip loss: 166.875\n",
            "total loss: 166.875\n",
            "iteration: 36\n",
            "clip loss: 166.25\n",
            "total loss: 166.25\n",
            "iteration: 37\n",
            "clip loss: 166.5\n",
            "total loss: 166.5\n",
            "iteration: 38\n",
            "clip loss: 166.25\n",
            "total loss: 166.25\n",
            "iteration: 39\n",
            "clip loss: 166.25\n",
            "total loss: 166.25\n",
            "iteration: 40\n",
            "clip loss: 166.5\n",
            "total loss: 166.5\n",
            "iteration: 41\n",
            "clip loss: 166.0\n",
            "total loss: 166.0\n",
            "iteration: 42\n",
            "clip loss: 165.625\n",
            "total loss: 165.625\n",
            "iteration: 43\n",
            "clip loss: 166.25\n",
            "total loss: 166.25\n",
            "iteration: 44\n",
            "clip loss: 165.5\n",
            "total loss: 165.5\n",
            "iteration: 45\n",
            "clip loss: 165.75\n",
            "total loss: 165.75\n",
            "iteration: 46\n",
            "clip loss: 165.375\n",
            "total loss: 165.375\n",
            "iteration: 47\n",
            "clip loss: 165.5\n",
            "total loss: 165.5\n",
            "iteration: 48\n",
            "clip loss: 165.25\n",
            "total loss: 165.25\n",
            "iteration: 49\n",
            "clip loss: 165.25\n",
            "total loss: 165.25\n",
            "iteration: 50\n",
            "clip loss: 165.375\n",
            "total loss: 165.375\n",
            "iteration: 51\n",
            "clip loss: 164.75\n",
            "total loss: 164.75\n",
            "iteration: 52\n",
            "clip loss: 164.75\n",
            "total loss: 164.75\n",
            "iteration: 53\n",
            "clip loss: 165.0\n",
            "total loss: 165.0\n",
            "iteration: 54\n",
            "clip loss: 164.875\n",
            "total loss: 164.875\n",
            "iteration: 55\n",
            "clip loss: 164.5\n",
            "total loss: 164.5\n",
            "iteration: 56\n",
            "clip loss: 164.375\n",
            "total loss: 164.375\n",
            "iteration: 57\n",
            "clip loss: 164.75\n",
            "total loss: 164.75\n",
            "iteration: 58\n",
            "clip loss: 164.5\n",
            "total loss: 164.5\n",
            "iteration: 59\n",
            "clip loss: 164.25\n",
            "total loss: 164.25\n",
            "iteration: 60\n",
            "clip loss: 164.375\n",
            "total loss: 164.375\n",
            "iteration: 61\n",
            "clip loss: 164.25\n",
            "total loss: 164.25\n",
            "iteration: 62\n",
            "clip loss: 163.875\n",
            "total loss: 163.875\n",
            "iteration: 63\n",
            "clip loss: 163.875\n",
            "total loss: 163.875\n",
            "iteration: 64\n",
            "clip loss: 163.625\n",
            "total loss: 163.625\n",
            "iteration: 65\n",
            "clip loss: 163.75\n",
            "total loss: 163.75\n",
            "iteration: 66\n",
            "clip loss: 163.75\n",
            "total loss: 163.75\n",
            "iteration: 67\n",
            "clip loss: 163.75\n",
            "total loss: 163.75\n",
            "iteration: 68\n",
            "clip loss: 163.25\n",
            "total loss: 163.25\n",
            "iteration: 69\n",
            "clip loss: 163.0\n",
            "total loss: 163.0\n",
            "iteration: 70\n",
            "clip loss: 163.25\n",
            "total loss: 163.25\n",
            "iteration: 71\n",
            "clip loss: 162.75\n",
            "total loss: 162.75\n",
            "iteration: 72\n",
            "clip loss: 162.875\n",
            "total loss: 162.875\n",
            "iteration: 73\n",
            "clip loss: 163.375\n",
            "total loss: 163.375\n",
            "iteration: 74\n",
            "clip loss: 163.0\n",
            "total loss: 163.0\n",
            "iteration: 75\n",
            "clip loss: 162.75\n",
            "total loss: 162.75\n",
            "iteration: 76\n",
            "clip loss: 162.625\n",
            "total loss: 162.625\n",
            "iteration: 77\n",
            "clip loss: 162.875\n",
            "total loss: 162.875\n",
            "iteration: 78\n",
            "clip loss: 162.875\n",
            "total loss: 162.875\n",
            "iteration: 79\n",
            "clip loss: 162.5\n",
            "total loss: 162.5\n",
            "iteration: 80\n",
            "clip loss: 162.375\n",
            "total loss: 162.375\n",
            "iteration: 81\n",
            "clip loss: 162.25\n",
            "total loss: 162.25\n",
            "iteration: 82\n",
            "clip loss: 162.125\n",
            "total loss: 162.125\n",
            "iteration: 83\n",
            "clip loss: 162.25\n",
            "total loss: 162.25\n",
            "iteration: 84\n",
            "clip loss: 161.75\n",
            "total loss: 161.75\n",
            "iteration: 85\n",
            "clip loss: 162.0\n",
            "total loss: 162.0\n",
            "iteration: 86\n",
            "clip loss: 162.0\n",
            "total loss: 162.0\n",
            "iteration: 87\n",
            "clip loss: 161.5\n",
            "total loss: 161.5\n",
            "iteration: 88\n",
            "clip loss: 161.75\n",
            "total loss: 161.75\n",
            "iteration: 89\n",
            "clip loss: 161.875\n",
            "total loss: 161.875\n",
            "iteration: 90\n",
            "clip loss: 161.625\n",
            "total loss: 161.625\n",
            "iteration: 91\n",
            "clip loss: 161.625\n",
            "total loss: 161.625\n",
            "iteration: 92\n",
            "clip loss: 161.375\n",
            "total loss: 161.375\n",
            "iteration: 93\n",
            "clip loss: 160.75\n",
            "total loss: 160.75\n",
            "iteration: 94\n",
            "clip loss: 161.125\n",
            "total loss: 161.125\n",
            "iteration: 95\n",
            "clip loss: 160.875\n",
            "total loss: 160.875\n",
            "iteration: 96\n",
            "clip loss: 161.375\n",
            "total loss: 161.375\n",
            "iteration: 97\n",
            "clip loss: 160.375\n",
            "total loss: 160.375\n",
            "iteration: 98\n",
            "clip loss: 160.625\n",
            "total loss: 160.625\n",
            "iteration: 99\n",
            "clip loss: 160.5\n",
            "total loss: 160.5\n",
            "iteration: 100\n",
            "clip loss: 160.75\n",
            "total loss: 160.75\n",
            "iteration: 101\n",
            "clip loss: 160.75\n",
            "total loss: 160.75\n",
            "iteration: 102\n",
            "clip loss: 160.5\n",
            "total loss: 160.5\n",
            "iteration: 103\n",
            "clip loss: 160.75\n",
            "total loss: 160.75\n",
            "iteration: 104\n",
            "clip loss: 160.5\n",
            "total loss: 160.5\n",
            "iteration: 105\n",
            "clip loss: 160.625\n",
            "total loss: 160.625\n",
            "iteration: 106\n",
            "clip loss: 160.875\n",
            "total loss: 160.875\n",
            "iteration: 107\n",
            "clip loss: 160.25\n",
            "total loss: 160.25\n",
            "iteration: 108\n",
            "clip loss: 160.25\n",
            "total loss: 160.25\n",
            "iteration: 109\n",
            "clip loss: 160.125\n",
            "total loss: 160.125\n",
            "iteration: 110\n",
            "clip loss: 159.5\n",
            "total loss: 159.5\n",
            "iteration: 111\n",
            "clip loss: 160.25\n",
            "total loss: 160.25\n",
            "iteration: 112\n",
            "clip loss: 159.875\n",
            "total loss: 159.875\n",
            "iteration: 113\n",
            "clip loss: 159.625\n",
            "total loss: 159.625\n",
            "iteration: 114\n",
            "clip loss: 160.0\n",
            "total loss: 160.0\n",
            "iteration: 115\n",
            "clip loss: 160.0\n",
            "total loss: 160.0\n",
            "iteration: 116\n",
            "clip loss: 159.625\n",
            "total loss: 159.625\n",
            "iteration: 117\n",
            "clip loss: 159.0\n",
            "total loss: 159.0\n",
            "iteration: 118\n",
            "clip loss: 159.25\n",
            "total loss: 159.25\n",
            "iteration: 119\n",
            "clip loss: 159.5\n",
            "total loss: 159.5\n",
            "iteration: 120\n",
            "clip loss: 159.5\n",
            "total loss: 159.5\n",
            "iteration: 121\n",
            "clip loss: 159.625\n",
            "total loss: 159.625\n",
            "iteration: 122\n",
            "clip loss: 159.625\n",
            "total loss: 159.625\n",
            "iteration: 123\n",
            "clip loss: 158.875\n",
            "total loss: 158.875\n",
            "iteration: 124\n",
            "clip loss: 158.875\n",
            "total loss: 158.875\n",
            "iteration: 125\n",
            "clip loss: 158.75\n",
            "total loss: 158.75\n",
            "iteration: 126\n",
            "clip loss: 158.875\n",
            "total loss: 158.875\n",
            "iteration: 127\n",
            "clip loss: 159.125\n",
            "total loss: 159.125\n",
            "iteration: 128\n",
            "clip loss: 159.25\n",
            "total loss: 159.25\n",
            "iteration: 129\n",
            "clip loss: 159.0\n",
            "total loss: 159.0\n",
            "iteration: 130\n",
            "clip loss: 158.5\n",
            "total loss: 158.5\n",
            "iteration: 131\n",
            "clip loss: 158.25\n",
            "total loss: 158.25\n",
            "iteration: 132\n",
            "clip loss: 158.375\n",
            "total loss: 158.375\n",
            "iteration: 133\n",
            "clip loss: 158.0\n",
            "total loss: 158.0\n",
            "iteration: 134\n",
            "clip loss: 158.375\n",
            "total loss: 158.375\n",
            "iteration: 135\n",
            "clip loss: 158.5\n",
            "total loss: 158.5\n",
            "iteration: 136\n",
            "clip loss: 158.375\n",
            "total loss: 158.375\n",
            "iteration: 137\n",
            "clip loss: 157.875\n",
            "total loss: 157.875\n",
            "iteration: 138\n",
            "clip loss: 158.5\n",
            "total loss: 158.5\n",
            "iteration: 139\n",
            "clip loss: 158.625\n",
            "total loss: 158.625\n",
            "iteration: 140\n",
            "clip loss: 157.625\n",
            "total loss: 157.625\n",
            "iteration: 141\n",
            "clip loss: 158.0\n",
            "total loss: 158.0\n",
            "iteration: 142\n",
            "clip loss: 157.375\n",
            "total loss: 157.375\n",
            "iteration: 143\n",
            "clip loss: 157.875\n",
            "total loss: 157.875\n",
            "iteration: 144\n",
            "clip loss: 158.0\n",
            "total loss: 158.0\n",
            "iteration: 145\n",
            "clip loss: 157.5\n",
            "total loss: 157.5\n",
            "iteration: 146\n",
            "clip loss: 157.875\n",
            "total loss: 157.875\n",
            "iteration: 147\n",
            "clip loss: 157.375\n",
            "total loss: 157.375\n",
            "iteration: 148\n",
            "clip loss: 157.125\n",
            "total loss: 157.125\n",
            "iteration: 149\n",
            "clip loss: 157.625\n",
            "total loss: 157.625\n"
          ]
        }
      ],
      "source": [
        "! cd path\n",
        "# ! python clipvg_baseline.py --svg imgs/Ac3.svg\n",
        "! python clipvg_font.py imgs/zifont3.svg imgs/nouse.jpeg"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Clipvg-run",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}